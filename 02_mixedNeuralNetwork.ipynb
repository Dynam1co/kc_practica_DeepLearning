{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "tf-gpu",
   "display_name": "TensorFlow-GPU"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal mixta con datos numéricos e imágenes\n",
    "Para esta parte, partimos de los datasets que teníamos ya separados en train y test y que contienen los datos numéricos. También usamos los que tenían almacenada la ruta de la imagen en el mismo orden que los datasets numéricos de train y test.\n",
    "\n",
    "Estos datasets los dejamos preparados en el notebook de tratamiento de datos. [Tratamiento de datos](limpiezaCategEscalado.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Carga el dataset y devuelve un dataframe de Pandas\n",
    "def load_airbnb_dataset(ruta,nombre):\n",
    "    csv_path = os.path.join(ruta, nombre)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carga de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_airbnb_dataset('datasets','trainFinal.csv')\n",
    "test = load_airbnb_dataset('datasets','testFinal.csv')\n",
    "dfTrainImagenes = load_airbnb_dataset('datasets','imagenesTrainFinal.csv')\n",
    "dfTestImagenes = load_airbnb_dataset('datasets','imagenesTestFinal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carga de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def cargaImagenes(dataF):\n",
    "    inputImages = []\n",
    "\n",
    "    origHeight = 144\n",
    "    origWidth = 216\n",
    "    origChann = 3\n",
    "\n",
    "    for ruta in dataF['imagenLocal']:\n",
    "        image = cv2.imread(ruta)\n",
    "\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        if (height != origHeight) or (width != origWidth) or (channels != origChann):\n",
    "            raise ValueError('Tamaño incorrecto en imagen:', ruta)\n",
    "        \n",
    "        inputImages.append(image)\n",
    "\n",
    "    return np.array(inputImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n(144, 216, 3)\n"
    }
   ],
   "source": [
    "imagenesTrain = cargaImagenes(dfTrainImagenes)\n",
    "imagenesTest = cargaImagenes(dfTestImagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Escalado de datos\n",
    "### Escalar imágenes en rango de 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenesTrain = imagenesTrain / 2550.\n",
    "imagenesTest = imagenesTest / 2550."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Escalar datos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo la Y del resto de datos\n",
    "dataPrecio = train['Price']\n",
    "dataSinPrecio = train.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "dataPrecioTest = test['Price']\n",
    "dataSinPrecioTest = test.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "y_train = dataPrecio.values\n",
    "X_train = dataSinPrecio.values\n",
    "\n",
    "y_test = dataPrecioTest.values\n",
    "X_test = dataSinPrecioTest.values\n",
    "\n",
    "feature_names = train.columns[:]\n",
    "\n",
    "# Obtener precio máximo en Train, y escalamos los precios de test y train en rango de [0, 1]\n",
    "maxPrice = train[\"Price\"].max()\n",
    "trainY = train[\"Price\"] / maxPrice\n",
    "testY = test[\"Price\"] / maxPrice\n",
    "\n",
    "# Escalamos variables numéricas de train y test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Red neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def create_mlp(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=dim, activation=\"relu\"))    \n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dense(1, activation=\"linear\"))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Red neuronal convolucional (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(10)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creación de modelos, concatenación MLP con CNN y generación modelo final\n",
    "Obtenemos ahora el modelo MLP y el CNN, luego los concatenamos y generamos un nuevo modelo con la unión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the MLP and CNN models\n",
    "mlp = create_mlp(XtrainScaled.shape[1])\n",
    "cnn = create_cnn(216, 144, 3, regress=False)\n",
    "\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compilamos y entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "historico = model.fit(\n",
    "\t[XtrainScaled, imagenesTrain], trainY,\n",
    "\tvalidation_data=([XtestScaled, imagenesTest], testY),\n",
    "\tepochs=200, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Curva de pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(0, 200), historico.history[\"loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluación del modelo combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}