{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "tf-gpu",
   "display_name": "TensorFlow-GPU"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal regresión con datos numéricos\n",
    "En ese notebook usaremos una red neuronal de regresión para predecir el precio de los apartamentos sin tener en cuenta las imágenes, se hará con datos numéricos.\n",
    "\n",
    "El primer paso será cargar dos datasets de train y test y hacer el escalado de características\n",
    "\n",
    "## Carga de datos y escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 5087621869623343280\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 3063309926\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 14484855071247566593\nphysical_device_desc: \"device: 0, name: GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:03:00.0, compute capability: 7.5\"\n]\ntf.Tensor(b'Hellow from TensorFlow 1.15.0', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n",
    "print( tf.constant( 'Hellow from TensorFlow ' + tf.__version__ ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Carga el dataset y devuelve un dataframe de Pandas\n",
    "def load_airbnb_dataset(ruta,nombre):\n",
    "    csv_path = os.path.join(ruta, nombre)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "copTrain = load_airbnb_dataset('datasets', 'trainFinal.csv')\n",
    "copTest = load_airbnb_dataset('datasets', 'testFinal.csv')\n",
    "\n",
    "# Separo la Y del resto de datos\n",
    "dataPrecio = copTrain['Price']\n",
    "dataSinPrecio = copTrain.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "dataPrecioTest = copTest['Price']\n",
    "dataSinPrecioTest = copTest.drop(['Price'], axis=1, inplace=False)\n",
    "\n",
    "y_train = dataPrecio.values\n",
    "X_train = dataSinPrecio.values\n",
    "\n",
    "y_test = dataPrecioTest.values\n",
    "X_test = dataSinPrecioTest.values\n",
    "\n",
    "feature_names = copTrain.columns[:]\n",
    "\n",
    "# Obtener precio máximo en Train, y escalamos los precios de test y train en rango de [0, 1]\n",
    "maxPrice = copTrain[\"Price\"].max()\n",
    "trainY = copTrain[\"Price\"] / maxPrice\n",
    "testY = copTest[\"Price\"] / maxPrice\n",
    "\n",
    "# Escalamos variables numéricas de train y test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "XtestScaled = scaler.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Red neuronal\n",
    "En este caso, usaremos una red neuronal (MLP) Multiplayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8262, 97)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Núemero de características\n",
    "XtrainScaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para calcular el nº de neuronas por capa oculta, uso la **Regla de la pirámide geométrica**.\n",
    "\n",
    "Tenemos 97 características (97 neuronas de entrada).\n",
    "Al ser un problema de regresión, tenemos una neurona de salida.\n",
    "\n",
    "Dividiré por 3 capas ocultas de la siguiente forma:\n",
    "\n",
    "r = raíz cuarta de 97/1\n",
    "r = 3\n",
    "\n",
    "h1 = 1 * 3^3 = 27\n",
    "\n",
    "h2 = 1 * 3^2 = 9\n",
    "\n",
    "h3 = 1 * 3 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def create_mlp(dim):\n",
    "\t# define our MLP network\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(27, input_dim=dim, activation=\"relu\"))\n",
    "\tmodel.add(Dense(9, activation=\"relu\"))\n",
    "\tmodel.add(Dense(3, activation=\"relu\"))\n",
    "\tmodel.add(Dense(1, activation=\"linear\"))\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.create_mlp(XtrainScaled.shape[1])\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "\tepochs=200, batch_size=8)"
   ]
  }
 ]
}